from typing import List, Set
import re


# -------------------------------------------------
# 1Ô∏è‚É£ Categor√≠as can√≥nicas de alergias (nivel m√©dico)
# -------------------------------------------------

ALLERGY_SYNONYMS = {
    "APLV": {
        "leche",
        "l√°cteos",
        "prote√≠na de leche",
        "case√≠na",
        "suero de leche",
        "milk",
        "dairy",
    },
    "HUEVO": {
        "huevo",
        "egg",
        "alb√∫mina",
    },
    "SOYA": {
        "soya",
        "soy",
        "lecitina de soya",
    },
    "FRUTOS_SECOS": {
        "nueces",
        "almendras",
        "avellanas",
        "man√≠",
        "peanuts",
        "tree nuts",
    },
}


# -------------------------------------------------
# 2Ô∏è‚É£ Normalizaci√≥n sem√°ntica de ingredientes
# -------------------------------------------------

INGREDIENT_NORMALIZATION = {
    # huevo
    "egg": "huevo",
    "eggs": "huevo",
    "alb√∫mina": "huevo",
    "huevo": "huevo",

    # leche
    "milk": "leche",
    "dairy": "leche",
    "case√≠na": "leche",
    "leche": "leche",

    # soya
    "soy": "soya",
    "soja": "soya",
    "soya": "soya",
}


# -------------------------------------------------
# 3Ô∏è‚É£ API P√öBLICA
# -------------------------------------------------

def normalize_allergies(raw_allergies: List[str]) -> Set[str]:
    """
    Maps user-provided allergy terms to canonical allergy labels.
    Example: ["egg", "leche"] ‚Üí {"HUEVO", "APLV"}
    """
    normalized = set()
    raw_lower = [a.lower().strip() for a in raw_allergies if a]

    for canonical, synonyms in ALLERGY_SYNONYMS.items():
        for term in raw_lower:
            if term in synonyms or term.upper() == canonical:
                normalized.add(canonical)

    return normalized


def normalize_ingredients(raw_ingredients: List[str]) -> Set[str]:
    """
    Normalizes ingredient names to a canonical semantic form.
    Example: ["egg", "milk"] ‚Üí {"huevo", "leche"}
    """
    normalized = set()

    for ingredient in raw_ingredients:
        if not ingredient:
            continue

        key = ingredient.lower().strip()
        normalized.add(INGREDIENT_NORMALIZATION.get(key, key))

    return normalized


# -------------------------------------------------
# 4Ô∏è‚É£ üî• DETECCI√ìN AUTOM√ÅTICA DESDE TEXTO LIBRE
# -------------------------------------------------

def detect_allergens_from_text(text: str) -> Set[str]:
    """
    Detects canonical allergens from free text.
    Example:
        "Bizcocho con egg y milk"
        ‚Üí {"HUEVO", "APLV"}
    """
    if not text:
        return set()

    detected = set()
    text_lower = text.lower()

    # tokenizaci√≥n simple y segura
    tokens = set(re.findall(r"\b\w+\b", text_lower))

    # normalizamos tokens sem√°nticamente
    normalized_tokens = {
        INGREDIENT_NORMALIZATION.get(token, token)
        for token in tokens
    }

    # mapeamos a categor√≠as m√©dicas
    for canonical, synonyms in ALLERGY_SYNONYMS.items():
        if normalized_tokens & synonyms:
            detected.add(canonical)

    return detected
